{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3fa0d5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import splitfolders\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import Model\n",
    "import scipy\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from matplotlib.patches import Rectangle\n",
    "from skimage.feature.peak import peak_local_max\n",
    "import random \n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a9c052f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 7324 files [00:30, 241.69 files/s]\n"
     ]
    }
   ],
   "source": [
    "input_dir = os.path.join('C:/Users/lydia/Documents/GitHub/Stroke_Daignosis_Detection/Dataset/')\n",
    "output_dir = os.path.join('C:/Users/lydia/Documents/GitHub/Stroke_Daignosis_Detection/Dataset2/')\n",
    "\n",
    "splitfolders.ratio(input_dir, output=output_dir, seed=1337, ratio=(.8,.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "630c572e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join('C:/Users/lydia/Documents/GitHub/Stroke_Daignosis_Detection/Dataset2/train/')\n",
    "val_dir = os.path.join('C:/Users/lydia/Documents/GitHub/Stroke_Daignosis_Detection/Dataset2/val/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e68db13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_generator(train_parent_directory, val_parent_directory):\n",
    "    train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "    val_datagen = ImageDataGenerator(rescale=1/255)\n",
    "    \n",
    "    train_generator = train_datagen.flow_from_directory(train_parent_directory,\n",
    "                                                       target_size=(224,224),\n",
    "                                                        batch_size=140,\n",
    "                                                        class_mode='categorical',\n",
    "                                                        subset='training')\n",
    "    \n",
    "    val_generator = val_datagen.flow_from_directory(val_parent_directory,\n",
    "                                                     target_size=(224,224),\n",
    "                                                      batch_size=37,\n",
    "                                                      class_mode='categorical')\n",
    "    \n",
    "    return train_generator, val_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f8fec33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5859 images belonging to 2 classes.\n",
      "Found 1465 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator, val_generator = image_generator(train_dir, val_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed422d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfd = tfp.distributions\n",
    "tfpl = tfp.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f106eb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\tensorflow_probability\\python\\layers\\util.py:95: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
      "  loc = add_variable_fn(\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorflow_probability\\python\\layers\\util.py:105: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
      "  untransformed_scale = add_variable_fn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_reparameterization (  (None, 217, 217, 4)      1544      \n",
      " Conv2DReparameterization)                                       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 108, 108, 4)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 106, 106, 32)      1184      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 53, 53, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 51, 51, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 25, 25, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 23, 23, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 11, 11, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 7744)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               3965440   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_reparameterization (D  (None, 2)                2052      \n",
      " enseReparameterization)                                         \n",
      "                                                                 \n",
      " one_hot_categorical (OneHot  ((None, 2),              0         \n",
      " Categorical)                 (None, 2))                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,025,644\n",
      "Trainable params: 4,025,644\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "divergence_fn = lambda q,p,_:tfd.kl_divergence(q,p)/8569\n",
    "\n",
    "model_bayes = Sequential([\n",
    "\n",
    "        tfpl.Convolution2DReparameterization(input_shape=(224,224,3), filters=4, kernel_size=8, activation='relu',\n",
    "                                               kernel_prior_fn = tfpl.default_multivariate_normal_fn,\n",
    "                                               kernel_posterior_fn=tfpl.default_mean_field_normal_fn(is_singular=False),\n",
    "                                               kernel_divergence_fn = divergence_fn,\n",
    "                                               bias_prior_fn = tfpl.default_multivariate_normal_fn,\n",
    "                                               bias_posterior_fn=tfpl.default_mean_field_normal_fn(is_singular=False),\n",
    "                                               bias_divergence_fn = divergence_fn),\n",
    "        MaxPooling2D(2,2),\n",
    "        Conv2D(32, (3,3), activation='relu'),\n",
    "        MaxPooling2D(2,2),\n",
    "        Conv2D(64, (3,3), activation='relu'),\n",
    "        MaxPooling2D(2,2),\n",
    "        Conv2D(64, (3,3), activation='relu'),\n",
    "        MaxPooling2D(2,2),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        tfpl.DenseReparameterization(units=tfpl.OneHotCategorical.params_size(2), activation=None,\n",
    "                                        kernel_prior_fn = tfpl.default_multivariate_normal_fn,\n",
    "                                        kernel_posterior_fn=tfpl.default_mean_field_normal_fn(is_singular=False),\n",
    "                                        kernel_divergence_fn = divergence_fn,\n",
    "                                        bias_prior_fn = tfpl.default_multivariate_normal_fn,\n",
    "                                        bias_posterior_fn=tfpl.default_mean_field_normal_fn(is_singular=False),\n",
    "                                        bias_divergence_fn = divergence_fn\n",
    "                                    ),\n",
    "        tfpl.OneHotCategorical(2)\n",
    "\n",
    "    ])\n",
    "    \n",
    "model_bayes.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3502b22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_log_likelihood(y_true, y_pred):\n",
    "    return -y_pred.log_prob(y_true)\n",
    "\n",
    "model_bayes.compile(loss = negative_log_likelihood,\n",
    "              optimizer = Adam(learning_rate=0.0001),\n",
    "              metrics = ['accuracy'],\n",
    "              experimental_run_tf_function = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5fe2a425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.2907 - accuracy: 0.9998 - val_loss: 0.3195 - val_accuracy: 0.9973\n",
      "Epoch 2/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.2898 - accuracy: 1.0000 - val_loss: 0.3225 - val_accuracy: 0.9980\n",
      "Epoch 3/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.2893 - accuracy: 0.9998 - val_loss: 0.3070 - val_accuracy: 0.9980\n",
      "Epoch 4/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.2885 - accuracy: 1.0000 - val_loss: 0.3067 - val_accuracy: 0.9980\n",
      "Epoch 5/500\n",
      "42/42 [==============================] - 143s 3s/step - loss: 0.2886 - accuracy: 0.9997 - val_loss: 0.3171 - val_accuracy: 0.9980\n",
      "Epoch 6/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.2877 - accuracy: 0.9995 - val_loss: 0.2952 - val_accuracy: 0.9973\n",
      "Epoch 7/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.2870 - accuracy: 0.9997 - val_loss: 0.3066 - val_accuracy: 0.9966\n",
      "Epoch 8/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.2861 - accuracy: 0.9997 - val_loss: 0.3117 - val_accuracy: 0.9966\n",
      "Epoch 9/500\n",
      "42/42 [==============================] - 146s 3s/step - loss: 0.2864 - accuracy: 0.9997 - val_loss: 0.3106 - val_accuracy: 0.9980\n",
      "Epoch 10/500\n",
      "42/42 [==============================] - 144s 3s/step - loss: 0.2849 - accuracy: 0.9998 - val_loss: 0.3075 - val_accuracy: 0.9980\n",
      "Epoch 11/500\n",
      "42/42 [==============================] - 143s 3s/step - loss: 0.2840 - accuracy: 1.0000 - val_loss: 0.3130 - val_accuracy: 0.9980\n",
      "Epoch 12/500\n",
      "42/42 [==============================] - 142s 3s/step - loss: 0.2834 - accuracy: 0.9998 - val_loss: 0.3017 - val_accuracy: 0.9973\n",
      "Epoch 13/500\n",
      "42/42 [==============================] - 141s 3s/step - loss: 0.2828 - accuracy: 1.0000 - val_loss: 0.3185 - val_accuracy: 0.9973\n",
      "Epoch 14/500\n",
      "42/42 [==============================] - 144s 3s/step - loss: 0.2822 - accuracy: 1.0000 - val_loss: 0.3039 - val_accuracy: 0.9966\n",
      "Epoch 15/500\n",
      "42/42 [==============================] - 144s 3s/step - loss: 0.2816 - accuracy: 1.0000 - val_loss: 0.3120 - val_accuracy: 0.9980\n",
      "Epoch 16/500\n",
      "42/42 [==============================] - 142s 3s/step - loss: 0.2809 - accuracy: 1.0000 - val_loss: 0.3067 - val_accuracy: 0.9980\n",
      "Epoch 17/500\n",
      "42/42 [==============================] - 142s 3s/step - loss: 0.2803 - accuracy: 0.9998 - val_loss: 0.3069 - val_accuracy: 0.9966\n",
      "Epoch 18/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.2798 - accuracy: 1.0000 - val_loss: 0.3025 - val_accuracy: 0.9980\n",
      "Epoch 19/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.2791 - accuracy: 1.0000 - val_loss: 0.3151 - val_accuracy: 0.9966\n",
      "Epoch 20/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.2909 - accuracy: 0.9971 - val_loss: 0.3052 - val_accuracy: 0.9952\n",
      "Epoch 21/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.2807 - accuracy: 0.9993 - val_loss: 0.2974 - val_accuracy: 0.9959\n",
      "Epoch 22/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.2779 - accuracy: 0.9998 - val_loss: 0.2888 - val_accuracy: 0.9980\n",
      "Epoch 23/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.2784 - accuracy: 0.9993 - val_loss: 0.2984 - val_accuracy: 0.9973\n",
      "Epoch 24/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.2778 - accuracy: 0.9986 - val_loss: 0.3139 - val_accuracy: 0.9966\n",
      "Epoch 25/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.2761 - accuracy: 1.0000 - val_loss: 0.2875 - val_accuracy: 0.9973\n",
      "Epoch 26/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.2756 - accuracy: 1.0000 - val_loss: 0.3011 - val_accuracy: 0.9980\n",
      "Epoch 27/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.2779 - accuracy: 0.9993 - val_loss: 0.2953 - val_accuracy: 0.9980\n",
      "Epoch 28/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.2747 - accuracy: 0.9997 - val_loss: 0.3061 - val_accuracy: 0.9973\n",
      "Epoch 29/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.2740 - accuracy: 1.0000 - val_loss: 0.2968 - val_accuracy: 0.9973\n",
      "Epoch 30/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.2737 - accuracy: 0.9998 - val_loss: 0.3022 - val_accuracy: 0.9973\n",
      "Epoch 31/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.2730 - accuracy: 0.9997 - val_loss: 0.3070 - val_accuracy: 0.9973\n",
      "Epoch 32/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.2725 - accuracy: 1.0000 - val_loss: 0.2859 - val_accuracy: 0.9980\n",
      "Epoch 33/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.2719 - accuracy: 1.0000 - val_loss: 0.2868 - val_accuracy: 0.9986\n",
      "Epoch 34/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.2714 - accuracy: 0.9998 - val_loss: 0.3011 - val_accuracy: 0.9973\n",
      "Epoch 35/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.2708 - accuracy: 1.0000 - val_loss: 0.2895 - val_accuracy: 0.9980\n",
      "Epoch 36/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.2703 - accuracy: 0.9998 - val_loss: 0.2880 - val_accuracy: 0.9973\n",
      "Epoch 37/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.2702 - accuracy: 0.9998 - val_loss: 0.2862 - val_accuracy: 0.9980\n",
      "Epoch 38/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.2692 - accuracy: 1.0000 - val_loss: 0.2864 - val_accuracy: 0.9980\n",
      "Epoch 39/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.2690 - accuracy: 0.9998 - val_loss: 0.2926 - val_accuracy: 0.9973\n",
      "Epoch 40/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.2688 - accuracy: 0.9995 - val_loss: 0.2918 - val_accuracy: 0.9973\n",
      "Epoch 41/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.2676 - accuracy: 1.0000 - val_loss: 0.2844 - val_accuracy: 0.9980\n",
      "Epoch 42/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.2678 - accuracy: 0.9993 - val_loss: 0.2898 - val_accuracy: 0.9980\n",
      "Epoch 43/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.2697 - accuracy: 0.9986 - val_loss: 0.2847 - val_accuracy: 0.9980\n",
      "Epoch 44/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.2676 - accuracy: 0.9993 - val_loss: 0.2745 - val_accuracy: 0.9980\n",
      "Epoch 45/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.2660 - accuracy: 0.9998 - val_loss: 0.2808 - val_accuracy: 0.9973\n",
      "Epoch 46/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.2652 - accuracy: 0.9997 - val_loss: 0.3006 - val_accuracy: 0.9952\n",
      "Epoch 47/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.2649 - accuracy: 0.9993 - val_loss: 0.2831 - val_accuracy: 0.9980\n",
      "Epoch 48/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.2658 - accuracy: 0.9997 - val_loss: 0.2795 - val_accuracy: 0.9980\n",
      "Epoch 49/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.2634 - accuracy: 1.0000 - val_loss: 0.2820 - val_accuracy: 0.9980\n",
      "Epoch 50/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.2642 - accuracy: 0.9995 - val_loss: 0.2810 - val_accuracy: 0.9973\n",
      "Epoch 51/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.2628 - accuracy: 0.9998 - val_loss: 0.2824 - val_accuracy: 0.9959\n",
      "Epoch 52/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.2618 - accuracy: 0.9998 - val_loss: 0.2751 - val_accuracy: 0.9980\n",
      "Epoch 53/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.2614 - accuracy: 1.0000 - val_loss: 0.2778 - val_accuracy: 0.9973\n",
      "Epoch 54/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.2624 - accuracy: 0.9993 - val_loss: 0.2790 - val_accuracy: 0.9980\n",
      "Epoch 55/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.2603 - accuracy: 0.9998 - val_loss: 0.2789 - val_accuracy: 0.9980\n",
      "Epoch 56/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.2598 - accuracy: 0.9997 - val_loss: 0.2671 - val_accuracy: 0.9986\n",
      "Epoch 57/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.2596 - accuracy: 0.9998 - val_loss: 0.2792 - val_accuracy: 0.9980\n",
      "Epoch 58/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 139s 3s/step - loss: 0.2597 - accuracy: 0.9995 - val_loss: 0.2820 - val_accuracy: 0.9966\n",
      "Epoch 59/500\n",
      "42/42 [==============================] - 141s 3s/step - loss: 0.2583 - accuracy: 0.9998 - val_loss: 0.2789 - val_accuracy: 0.9973\n",
      "Epoch 60/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.2578 - accuracy: 0.9997 - val_loss: 0.2701 - val_accuracy: 0.9986\n",
      "Epoch 61/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.2572 - accuracy: 0.9998 - val_loss: 0.2673 - val_accuracy: 0.9986\n",
      "Epoch 62/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.2565 - accuracy: 1.0000 - val_loss: 0.2677 - val_accuracy: 0.9980\n",
      "Epoch 63/500\n",
      "42/42 [==============================] - 143s 3s/step - loss: 0.2560 - accuracy: 0.9998 - val_loss: 0.2733 - val_accuracy: 0.9986\n",
      "Epoch 64/500\n",
      "42/42 [==============================] - 153s 4s/step - loss: 0.2554 - accuracy: 1.0000 - val_loss: 0.2734 - val_accuracy: 0.9973\n",
      "Epoch 65/500\n",
      "42/42 [==============================] - 148s 4s/step - loss: 0.2548 - accuracy: 1.0000 - val_loss: 0.2746 - val_accuracy: 0.9980\n",
      "Epoch 66/500\n",
      "42/42 [==============================] - 141s 3s/step - loss: 0.2548 - accuracy: 0.9998 - val_loss: 0.2756 - val_accuracy: 0.9973\n",
      "Epoch 67/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.2539 - accuracy: 1.0000 - val_loss: 0.2803 - val_accuracy: 0.9980\n",
      "Epoch 68/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.2539 - accuracy: 0.9997 - val_loss: 0.2671 - val_accuracy: 0.9973\n",
      "Epoch 69/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.2527 - accuracy: 0.9998 - val_loss: 0.2649 - val_accuracy: 0.9986\n",
      "Epoch 70/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.2523 - accuracy: 1.0000 - val_loss: 0.2603 - val_accuracy: 0.9986\n",
      "Epoch 71/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.2515 - accuracy: 1.0000 - val_loss: 0.2791 - val_accuracy: 0.9973\n",
      "Epoch 72/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.2511 - accuracy: 0.9997 - val_loss: 0.2854 - val_accuracy: 0.9966\n",
      "Epoch 73/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.2512 - accuracy: 0.9995 - val_loss: 0.2745 - val_accuracy: 0.9966\n",
      "Epoch 74/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.2505 - accuracy: 0.9997 - val_loss: 0.2648 - val_accuracy: 0.9980\n",
      "Epoch 75/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.2495 - accuracy: 0.9998 - val_loss: 0.2664 - val_accuracy: 0.9973\n",
      "Epoch 76/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.2487 - accuracy: 1.0000 - val_loss: 0.2626 - val_accuracy: 0.9980\n",
      "Epoch 77/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.2481 - accuracy: 1.0000 - val_loss: 0.2711 - val_accuracy: 0.9980\n",
      "Epoch 78/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.2475 - accuracy: 0.9998 - val_loss: 0.2757 - val_accuracy: 0.9980\n",
      "Epoch 79/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.2470 - accuracy: 1.0000 - val_loss: 0.2686 - val_accuracy: 0.9973\n",
      "Epoch 80/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.2466 - accuracy: 0.9997 - val_loss: 0.2632 - val_accuracy: 0.9980\n",
      "Epoch 81/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.2459 - accuracy: 0.9998 - val_loss: 0.2608 - val_accuracy: 0.9980\n",
      "Epoch 82/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.2452 - accuracy: 1.0000 - val_loss: 0.2717 - val_accuracy: 0.9973\n",
      "Epoch 83/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.2448 - accuracy: 1.0000 - val_loss: 0.2695 - val_accuracy: 0.9980\n",
      "Epoch 84/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.2441 - accuracy: 1.0000 - val_loss: 0.2516 - val_accuracy: 0.9986\n",
      "Epoch 85/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.2448 - accuracy: 0.9997 - val_loss: 0.2538 - val_accuracy: 0.9973\n",
      "Epoch 86/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.2430 - accuracy: 1.0000 - val_loss: 0.2538 - val_accuracy: 0.9986\n",
      "Epoch 87/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.2423 - accuracy: 1.0000 - val_loss: 0.2614 - val_accuracy: 0.9973\n",
      "Epoch 88/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.2418 - accuracy: 1.0000 - val_loss: 0.2571 - val_accuracy: 0.9986\n",
      "Epoch 89/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.2412 - accuracy: 1.0000 - val_loss: 0.2608 - val_accuracy: 0.9980\n",
      "Epoch 90/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.2406 - accuracy: 1.0000 - val_loss: 0.2547 - val_accuracy: 0.9973\n",
      "Epoch 91/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.2401 - accuracy: 0.9998 - val_loss: 0.2572 - val_accuracy: 0.9966\n",
      "Epoch 92/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.2393 - accuracy: 0.9998 - val_loss: 0.2547 - val_accuracy: 0.9973\n",
      "Epoch 93/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.2392 - accuracy: 0.9993 - val_loss: 0.2623 - val_accuracy: 0.9980\n",
      "Epoch 94/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.2387 - accuracy: 0.9991 - val_loss: 0.2583 - val_accuracy: 0.9966\n",
      "Epoch 95/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.2377 - accuracy: 0.9997 - val_loss: 0.2587 - val_accuracy: 0.9980\n",
      "Epoch 96/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.2387 - accuracy: 0.9998 - val_loss: 0.2495 - val_accuracy: 0.9986\n",
      "Epoch 97/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.2365 - accuracy: 0.9998 - val_loss: 0.2605 - val_accuracy: 0.9973\n",
      "Epoch 98/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.2371 - accuracy: 0.9995 - val_loss: 0.2613 - val_accuracy: 0.9973\n",
      "Epoch 99/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.2378 - accuracy: 0.9988 - val_loss: 0.2745 - val_accuracy: 0.9973\n",
      "Epoch 100/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.2362 - accuracy: 0.9986 - val_loss: 0.2618 - val_accuracy: 0.9966\n",
      "Epoch 101/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.2345 - accuracy: 0.9995 - val_loss: 0.2396 - val_accuracy: 0.9986\n",
      "Epoch 102/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.2347 - accuracy: 0.9995 - val_loss: 0.2591 - val_accuracy: 0.9973\n",
      "Epoch 103/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.2338 - accuracy: 0.9998 - val_loss: 0.2455 - val_accuracy: 0.9973\n",
      "Epoch 104/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.2346 - accuracy: 0.9991 - val_loss: 0.2445 - val_accuracy: 0.9980\n",
      "Epoch 105/500\n",
      "42/42 [==============================] - 141s 3s/step - loss: 0.2336 - accuracy: 0.9991 - val_loss: 0.2547 - val_accuracy: 0.9973\n",
      "Epoch 106/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.2330 - accuracy: 0.9995 - val_loss: 0.2412 - val_accuracy: 0.9980\n",
      "Epoch 107/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.2321 - accuracy: 0.9995 - val_loss: 0.2491 - val_accuracy: 0.9973\n",
      "Epoch 108/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.2311 - accuracy: 0.9997 - val_loss: 0.2424 - val_accuracy: 0.9980\n",
      "Epoch 109/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.2308 - accuracy: 0.9995 - val_loss: 0.2542 - val_accuracy: 0.9980\n",
      "Epoch 110/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.2298 - accuracy: 1.0000 - val_loss: 0.2609 - val_accuracy: 0.9980\n",
      "Epoch 111/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.2292 - accuracy: 1.0000 - val_loss: 0.2632 - val_accuracy: 0.9980\n",
      "Epoch 112/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.2287 - accuracy: 1.0000 - val_loss: 0.2510 - val_accuracy: 0.9980\n",
      "Epoch 113/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.2281 - accuracy: 0.9998 - val_loss: 0.2522 - val_accuracy: 0.9973\n",
      "Epoch 114/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.2279 - accuracy: 0.9997 - val_loss: 0.2409 - val_accuracy: 0.9966\n",
      "Epoch 115/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 140s 3s/step - loss: 0.2272 - accuracy: 1.0000 - val_loss: 0.2523 - val_accuracy: 0.9966\n",
      "Epoch 116/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.2272 - accuracy: 1.0000 - val_loss: 0.2479 - val_accuracy: 0.9980\n",
      "Epoch 117/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.2266 - accuracy: 0.9997 - val_loss: 0.2408 - val_accuracy: 0.9973\n",
      "Epoch 118/500\n",
      "42/42 [==============================] - 141s 3s/step - loss: 0.2277 - accuracy: 0.9995 - val_loss: 0.2522 - val_accuracy: 0.9945\n",
      "Epoch 119/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.2257 - accuracy: 0.9995 - val_loss: 0.2422 - val_accuracy: 0.9973\n",
      "Epoch 120/500\n",
      "42/42 [==============================] - 141s 3s/step - loss: 0.2252 - accuracy: 0.9998 - val_loss: 0.2379 - val_accuracy: 0.9986\n",
      "Epoch 121/500\n",
      "42/42 [==============================] - 141s 3s/step - loss: 0.2243 - accuracy: 0.9997 - val_loss: 0.2404 - val_accuracy: 0.9973\n",
      "Epoch 122/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.2242 - accuracy: 0.9997 - val_loss: 0.2458 - val_accuracy: 0.9973\n",
      "Epoch 123/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.2238 - accuracy: 0.9997 - val_loss: 0.2605 - val_accuracy: 0.9973\n",
      "Epoch 124/500\n",
      "42/42 [==============================] - 141s 3s/step - loss: 0.2247 - accuracy: 0.9993 - val_loss: 0.2480 - val_accuracy: 0.9973\n",
      "Epoch 125/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.2224 - accuracy: 1.0000 - val_loss: 0.2517 - val_accuracy: 0.9980\n",
      "Epoch 126/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.2218 - accuracy: 0.9998 - val_loss: 0.2477 - val_accuracy: 0.9973\n",
      "Epoch 127/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.2213 - accuracy: 1.0000 - val_loss: 0.2666 - val_accuracy: 0.9973\n",
      "Epoch 128/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.2208 - accuracy: 1.0000 - val_loss: 0.2551 - val_accuracy: 0.9980\n",
      "Epoch 129/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.2211 - accuracy: 0.9997 - val_loss: 0.2327 - val_accuracy: 0.9980\n",
      "Epoch 130/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.2222 - accuracy: 0.9988 - val_loss: 0.2298 - val_accuracy: 0.9986\n",
      "Epoch 131/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.2200 - accuracy: 0.9995 - val_loss: 0.2437 - val_accuracy: 0.9980\n",
      "Epoch 132/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.2191 - accuracy: 1.0000 - val_loss: 0.2333 - val_accuracy: 0.9986\n",
      "Epoch 133/500\n",
      "42/42 [==============================] - 141s 3s/step - loss: 0.2187 - accuracy: 0.9997 - val_loss: 0.2333 - val_accuracy: 0.9980\n",
      "Epoch 134/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.2180 - accuracy: 1.0000 - val_loss: 0.2370 - val_accuracy: 0.9980\n",
      "Epoch 135/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.2177 - accuracy: 0.9997 - val_loss: 0.2469 - val_accuracy: 0.9980\n",
      "Epoch 136/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.2170 - accuracy: 1.0000 - val_loss: 0.2377 - val_accuracy: 0.9980\n",
      "Epoch 137/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.2165 - accuracy: 1.0000 - val_loss: 0.2376 - val_accuracy: 0.9986\n",
      "Epoch 138/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.2161 - accuracy: 1.0000 - val_loss: 0.2291 - val_accuracy: 0.9986\n",
      "Epoch 139/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.2155 - accuracy: 1.0000 - val_loss: 0.2433 - val_accuracy: 0.9986\n",
      "Epoch 140/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.2150 - accuracy: 1.0000 - val_loss: 0.2393 - val_accuracy: 0.9980\n",
      "Epoch 141/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.2146 - accuracy: 0.9998 - val_loss: 0.2483 - val_accuracy: 0.9980\n",
      "Epoch 142/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.2149 - accuracy: 0.9998 - val_loss: 0.2279 - val_accuracy: 0.9980\n",
      "Epoch 143/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.2136 - accuracy: 1.0000 - val_loss: 0.2395 - val_accuracy: 0.9973\n",
      "Epoch 144/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.2137 - accuracy: 0.9998 - val_loss: 0.2623 - val_accuracy: 0.9973\n",
      "Epoch 145/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.2126 - accuracy: 1.0000 - val_loss: 0.2358 - val_accuracy: 0.9980\n",
      "Epoch 146/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.2120 - accuracy: 1.0000 - val_loss: 0.2478 - val_accuracy: 0.9980\n",
      "Epoch 147/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.2116 - accuracy: 1.0000 - val_loss: 0.2463 - val_accuracy: 0.9980\n",
      "Epoch 148/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.2110 - accuracy: 1.0000 - val_loss: 0.2476 - val_accuracy: 0.9980\n",
      "Epoch 149/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.2105 - accuracy: 1.0000 - val_loss: 0.2414 - val_accuracy: 0.9973\n",
      "Epoch 150/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.2103 - accuracy: 0.9998 - val_loss: 0.2431 - val_accuracy: 0.9980\n",
      "Epoch 151/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.2136 - accuracy: 0.9991 - val_loss: 0.2318 - val_accuracy: 0.9966\n",
      "Epoch 152/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.2120 - accuracy: 0.9985 - val_loss: 0.2287 - val_accuracy: 0.9980\n",
      "Epoch 153/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.2118 - accuracy: 0.9983 - val_loss: 0.2295 - val_accuracy: 0.9973\n",
      "Epoch 154/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.2086 - accuracy: 0.9995 - val_loss: 0.2211 - val_accuracy: 0.9980\n",
      "Epoch 155/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.2098 - accuracy: 0.9990 - val_loss: 0.2213 - val_accuracy: 0.9986\n",
      "Epoch 156/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.2085 - accuracy: 0.9993 - val_loss: 0.2193 - val_accuracy: 0.9980\n",
      "Epoch 157/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.2069 - accuracy: 1.0000 - val_loss: 0.2320 - val_accuracy: 0.9973\n",
      "Epoch 158/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.2070 - accuracy: 0.9997 - val_loss: 0.2251 - val_accuracy: 0.9973\n",
      "Epoch 159/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.2062 - accuracy: 1.0000 - val_loss: 0.2296 - val_accuracy: 0.9973\n",
      "Epoch 160/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.2061 - accuracy: 0.9998 - val_loss: 0.2156 - val_accuracy: 0.9986\n",
      "Epoch 161/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.2052 - accuracy: 0.9998 - val_loss: 0.2134 - val_accuracy: 0.9980\n",
      "Epoch 162/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.2048 - accuracy: 0.9998 - val_loss: 0.2302 - val_accuracy: 0.9980\n",
      "Epoch 163/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.2042 - accuracy: 1.0000 - val_loss: 0.2210 - val_accuracy: 0.9986\n",
      "Epoch 164/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.2038 - accuracy: 1.0000 - val_loss: 0.2275 - val_accuracy: 0.9973\n",
      "Epoch 165/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.2033 - accuracy: 0.9997 - val_loss: 0.2400 - val_accuracy: 0.9966\n",
      "Epoch 166/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.2030 - accuracy: 1.0000 - val_loss: 0.2203 - val_accuracy: 0.9986\n",
      "Epoch 167/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.2037 - accuracy: 0.9993 - val_loss: 0.2225 - val_accuracy: 0.9980\n",
      "Epoch 168/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.2029 - accuracy: 0.9997 - val_loss: 0.2293 - val_accuracy: 0.9973\n",
      "Epoch 169/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.2018 - accuracy: 0.9997 - val_loss: 0.2275 - val_accuracy: 0.9980\n",
      "Epoch 170/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.2010 - accuracy: 1.0000 - val_loss: 0.2181 - val_accuracy: 0.9980\n",
      "Epoch 171/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.2021 - accuracy: 0.9993 - val_loss: 0.2193 - val_accuracy: 0.9986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.2011 - accuracy: 0.9997 - val_loss: 0.2171 - val_accuracy: 0.9980\n",
      "Epoch 173/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.2020 - accuracy: 0.9993 - val_loss: 0.2093 - val_accuracy: 0.9986\n",
      "Epoch 174/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.1996 - accuracy: 0.9997 - val_loss: 0.2087 - val_accuracy: 0.9993\n",
      "Epoch 175/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.1997 - accuracy: 0.9995 - val_loss: 0.2245 - val_accuracy: 0.9980\n",
      "Epoch 176/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.1999 - accuracy: 0.9995 - val_loss: 0.2313 - val_accuracy: 0.9980\n",
      "Epoch 177/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.1981 - accuracy: 1.0000 - val_loss: 0.2212 - val_accuracy: 0.9980\n",
      "Epoch 178/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.1980 - accuracy: 0.9997 - val_loss: 0.2281 - val_accuracy: 0.9980\n",
      "Epoch 179/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.1978 - accuracy: 0.9997 - val_loss: 0.2231 - val_accuracy: 0.9986\n",
      "Epoch 180/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.1968 - accuracy: 0.9998 - val_loss: 0.2224 - val_accuracy: 0.9973\n",
      "Epoch 181/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.1963 - accuracy: 1.0000 - val_loss: 0.2132 - val_accuracy: 0.9980\n",
      "Epoch 182/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.1958 - accuracy: 1.0000 - val_loss: 0.2222 - val_accuracy: 0.9980\n",
      "Epoch 183/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.1954 - accuracy: 1.0000 - val_loss: 0.2138 - val_accuracy: 0.9980\n",
      "Epoch 184/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.1953 - accuracy: 0.9998 - val_loss: 0.2288 - val_accuracy: 0.9980\n",
      "Epoch 185/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.1958 - accuracy: 0.9997 - val_loss: 0.2137 - val_accuracy: 0.9986\n",
      "Epoch 186/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.1967 - accuracy: 0.9993 - val_loss: 0.2158 - val_accuracy: 0.9980\n",
      "Epoch 187/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.1938 - accuracy: 0.9998 - val_loss: 0.2125 - val_accuracy: 0.9980\n",
      "Epoch 188/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.1936 - accuracy: 0.9995 - val_loss: 0.2117 - val_accuracy: 0.9993\n",
      "Epoch 189/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.1929 - accuracy: 1.0000 - val_loss: 0.2240 - val_accuracy: 0.9973\n",
      "Epoch 190/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.1936 - accuracy: 0.9997 - val_loss: 0.2022 - val_accuracy: 0.9980\n",
      "Epoch 191/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.1924 - accuracy: 0.9995 - val_loss: 0.2231 - val_accuracy: 0.9966\n",
      "Epoch 192/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.1918 - accuracy: 0.9995 - val_loss: 0.2154 - val_accuracy: 0.9980\n",
      "Epoch 193/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.1915 - accuracy: 0.9998 - val_loss: 0.2289 - val_accuracy: 0.9973\n",
      "Epoch 194/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.1905 - accuracy: 1.0000 - val_loss: 0.2360 - val_accuracy: 0.9980\n",
      "Epoch 195/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.1902 - accuracy: 1.0000 - val_loss: 0.1950 - val_accuracy: 0.9980\n",
      "Epoch 196/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.1896 - accuracy: 0.9998 - val_loss: 0.2161 - val_accuracy: 0.9980\n",
      "Epoch 197/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.1894 - accuracy: 0.9998 - val_loss: 0.2146 - val_accuracy: 0.9966\n",
      "Epoch 198/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.1889 - accuracy: 0.9997 - val_loss: 0.1959 - val_accuracy: 0.9993\n",
      "Epoch 199/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.1884 - accuracy: 0.9998 - val_loss: 0.2083 - val_accuracy: 0.9986\n",
      "Epoch 200/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.1892 - accuracy: 0.9993 - val_loss: 0.2233 - val_accuracy: 0.9966\n",
      "Epoch 201/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.1874 - accuracy: 1.0000 - val_loss: 0.2141 - val_accuracy: 0.9980\n",
      "Epoch 202/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.1873 - accuracy: 0.9995 - val_loss: 0.2019 - val_accuracy: 0.9980\n",
      "Epoch 203/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.1865 - accuracy: 1.0000 - val_loss: 0.2194 - val_accuracy: 0.9980\n",
      "Epoch 204/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.1860 - accuracy: 1.0000 - val_loss: 0.2125 - val_accuracy: 0.9980\n",
      "Epoch 205/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.1855 - accuracy: 1.0000 - val_loss: 0.2166 - val_accuracy: 0.9980\n",
      "Epoch 206/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.1850 - accuracy: 1.0000 - val_loss: 0.1911 - val_accuracy: 0.9993\n",
      "Epoch 207/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.1847 - accuracy: 1.0000 - val_loss: 0.2067 - val_accuracy: 0.9980\n",
      "Epoch 208/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.1841 - accuracy: 1.0000 - val_loss: 0.1913 - val_accuracy: 0.9980\n",
      "Epoch 209/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.1837 - accuracy: 1.0000 - val_loss: 0.2078 - val_accuracy: 0.9980\n",
      "Epoch 210/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.1832 - accuracy: 0.9998 - val_loss: 0.2030 - val_accuracy: 0.9980\n",
      "Epoch 211/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.1827 - accuracy: 0.9998 - val_loss: 0.2141 - val_accuracy: 0.9980\n",
      "Epoch 212/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.1824 - accuracy: 0.9998 - val_loss: 0.2097 - val_accuracy: 0.9980\n",
      "Epoch 213/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.1817 - accuracy: 1.0000 - val_loss: 0.1934 - val_accuracy: 0.9986\n",
      "Epoch 214/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.1813 - accuracy: 1.0000 - val_loss: 0.2175 - val_accuracy: 0.9973\n",
      "Epoch 215/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.1807 - accuracy: 1.0000 - val_loss: 0.1991 - val_accuracy: 0.9980\n",
      "Epoch 216/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.1802 - accuracy: 1.0000 - val_loss: 0.2030 - val_accuracy: 0.9980\n",
      "Epoch 217/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.1798 - accuracy: 0.9998 - val_loss: 0.2264 - val_accuracy: 0.9980\n",
      "Epoch 218/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.1795 - accuracy: 0.9993 - val_loss: 0.2071 - val_accuracy: 0.9980\n",
      "Epoch 219/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.1788 - accuracy: 0.9998 - val_loss: 0.2105 - val_accuracy: 0.9980\n",
      "Epoch 220/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.1812 - accuracy: 0.9995 - val_loss: 0.2079 - val_accuracy: 0.9980\n",
      "Epoch 221/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.1790 - accuracy: 0.9991 - val_loss: 0.2005 - val_accuracy: 0.9973\n",
      "Epoch 222/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.1804 - accuracy: 0.9991 - val_loss: 0.2065 - val_accuracy: 0.9959\n",
      "Epoch 223/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.1819 - accuracy: 0.9986 - val_loss: 0.2204 - val_accuracy: 0.9966\n",
      "Epoch 224/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.1780 - accuracy: 0.9993 - val_loss: 0.2114 - val_accuracy: 0.9959\n",
      "Epoch 225/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.1784 - accuracy: 0.9993 - val_loss: 0.2063 - val_accuracy: 0.9980\n",
      "Epoch 226/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.1758 - accuracy: 0.9998 - val_loss: 0.2060 - val_accuracy: 0.9980\n",
      "Epoch 227/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.1755 - accuracy: 0.9997 - val_loss: 0.2153 - val_accuracy: 0.9980\n",
      "Epoch 228/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.1749 - accuracy: 1.0000 - val_loss: 0.2111 - val_accuracy: 0.9980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.1746 - accuracy: 0.9998 - val_loss: 0.1989 - val_accuracy: 0.9980\n",
      "Epoch 230/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.1742 - accuracy: 0.9998 - val_loss: 0.2108 - val_accuracy: 0.9980\n",
      "Epoch 231/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.1740 - accuracy: 0.9998 - val_loss: 0.2077 - val_accuracy: 0.9980\n",
      "Epoch 232/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.1733 - accuracy: 0.9998 - val_loss: 0.1966 - val_accuracy: 0.9973\n",
      "Epoch 233/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.1728 - accuracy: 1.0000 - val_loss: 0.1923 - val_accuracy: 0.9973\n",
      "Epoch 234/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.1723 - accuracy: 1.0000 - val_loss: 0.1846 - val_accuracy: 0.9980\n",
      "Epoch 235/500\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.1726 - accuracy: 0.9997 - val_loss: 0.1877 - val_accuracy: 0.9986\n",
      "Epoch 236/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.1715 - accuracy: 1.0000 - val_loss: 0.1974 - val_accuracy: 0.9980\n",
      "Epoch 237/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.1710 - accuracy: 1.0000 - val_loss: 0.1935 - val_accuracy: 0.9986\n",
      "Epoch 238/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.1714 - accuracy: 0.9995 - val_loss: 0.1956 - val_accuracy: 0.9986\n",
      "Epoch 239/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.1708 - accuracy: 0.9997 - val_loss: 0.1846 - val_accuracy: 0.9973\n",
      "Epoch 240/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.1704 - accuracy: 0.9998 - val_loss: 0.2081 - val_accuracy: 0.9980\n",
      "Epoch 241/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.1693 - accuracy: 1.0000 - val_loss: 0.1852 - val_accuracy: 0.9980\n",
      "Epoch 242/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.1690 - accuracy: 1.0000 - val_loss: 0.1869 - val_accuracy: 0.9980\n",
      "Epoch 243/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.1696 - accuracy: 0.9998 - val_loss: 0.1928 - val_accuracy: 0.9959\n",
      "Epoch 244/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.1692 - accuracy: 0.9997 - val_loss: 0.2037 - val_accuracy: 0.9973\n",
      "Epoch 245/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.1684 - accuracy: 0.9995 - val_loss: 0.1923 - val_accuracy: 0.9980\n",
      "Epoch 246/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.1680 - accuracy: 0.9997 - val_loss: 0.2097 - val_accuracy: 0.9966\n",
      "Epoch 247/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.1668 - accuracy: 1.0000 - val_loss: 0.2259 - val_accuracy: 0.9973\n",
      "Epoch 248/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.1664 - accuracy: 1.0000 - val_loss: 0.2200 - val_accuracy: 0.9973\n",
      "Epoch 249/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.1671 - accuracy: 0.9995 - val_loss: 0.1844 - val_accuracy: 0.9966\n",
      "Epoch 250/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.1670 - accuracy: 0.9995 - val_loss: 0.1751 - val_accuracy: 0.9980\n",
      "Epoch 251/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.1667 - accuracy: 0.9993 - val_loss: 0.1740 - val_accuracy: 0.9986\n",
      "Epoch 252/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.1657 - accuracy: 0.9993 - val_loss: 0.1866 - val_accuracy: 0.9973\n",
      "Epoch 253/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.1651 - accuracy: 0.9997 - val_loss: 0.1896 - val_accuracy: 0.9973\n",
      "Epoch 254/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.1643 - accuracy: 0.9995 - val_loss: 0.1911 - val_accuracy: 0.9973\n",
      "Epoch 255/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.1641 - accuracy: 0.9997 - val_loss: 0.1803 - val_accuracy: 0.9973\n",
      "Epoch 256/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.1635 - accuracy: 1.0000 - val_loss: 0.1834 - val_accuracy: 0.9980\n",
      "Epoch 257/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.1629 - accuracy: 1.0000 - val_loss: 0.2146 - val_accuracy: 0.9980\n",
      "Epoch 258/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.1628 - accuracy: 0.9997 - val_loss: 0.1894 - val_accuracy: 0.9980\n",
      "Epoch 259/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.1624 - accuracy: 0.9998 - val_loss: 0.1869 - val_accuracy: 0.9980\n",
      "Epoch 260/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.1623 - accuracy: 0.9998 - val_loss: 0.1791 - val_accuracy: 0.9973\n",
      "Epoch 261/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.1616 - accuracy: 0.9995 - val_loss: 0.1939 - val_accuracy: 0.9980\n",
      "Epoch 262/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.1611 - accuracy: 0.9998 - val_loss: 0.1746 - val_accuracy: 0.9986\n",
      "Epoch 263/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.1605 - accuracy: 1.0000 - val_loss: 0.1826 - val_accuracy: 0.9980\n",
      "Epoch 264/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.1602 - accuracy: 1.0000 - val_loss: 0.1741 - val_accuracy: 0.9986\n",
      "Epoch 265/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.1600 - accuracy: 0.9998 - val_loss: 0.1731 - val_accuracy: 0.9973\n",
      "Epoch 266/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.1616 - accuracy: 0.9995 - val_loss: 0.1799 - val_accuracy: 0.9980\n",
      "Epoch 267/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.1605 - accuracy: 0.9993 - val_loss: 0.1793 - val_accuracy: 0.9980\n",
      "Epoch 268/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.1584 - accuracy: 1.0000 - val_loss: 0.1716 - val_accuracy: 0.9993\n",
      "Epoch 269/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.1582 - accuracy: 1.0000 - val_loss: 0.1644 - val_accuracy: 0.9980\n",
      "Epoch 270/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.1578 - accuracy: 0.9997 - val_loss: 0.1768 - val_accuracy: 0.9986\n",
      "Epoch 271/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.1572 - accuracy: 1.0000 - val_loss: 0.1810 - val_accuracy: 0.9980\n",
      "Epoch 272/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.1568 - accuracy: 1.0000 - val_loss: 0.1676 - val_accuracy: 0.9986\n",
      "Epoch 273/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.1564 - accuracy: 1.0000 - val_loss: 0.1780 - val_accuracy: 0.9973\n",
      "Epoch 274/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.1560 - accuracy: 1.0000 - val_loss: 0.1719 - val_accuracy: 0.9980\n",
      "Epoch 275/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1556 - accuracy: 0.9998 - val_loss: 0.1735 - val_accuracy: 0.9986\n",
      "Epoch 276/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.1551 - accuracy: 1.0000 - val_loss: 0.1707 - val_accuracy: 0.9980\n",
      "Epoch 277/500\n",
      "42/42 [==============================] - 139s 3s/step - loss: 0.1547 - accuracy: 1.0000 - val_loss: 0.1601 - val_accuracy: 0.9993\n",
      "Epoch 278/500\n",
      "42/42 [==============================] - 134s 3s/step - loss: 0.1544 - accuracy: 0.9997 - val_loss: 0.1562 - val_accuracy: 0.9993\n",
      "Epoch 279/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.1551 - accuracy: 0.9997 - val_loss: 0.2170 - val_accuracy: 0.9973\n",
      "Epoch 280/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.1561 - accuracy: 0.9991 - val_loss: 0.1725 - val_accuracy: 0.9973\n",
      "Epoch 281/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1534 - accuracy: 0.9998 - val_loss: 0.1623 - val_accuracy: 0.9980\n",
      "Epoch 282/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.1533 - accuracy: 0.9995 - val_loss: 0.1608 - val_accuracy: 0.9986\n",
      "Epoch 283/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.1529 - accuracy: 0.9997 - val_loss: 0.1766 - val_accuracy: 0.9986\n",
      "Epoch 284/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.1573 - accuracy: 0.9988 - val_loss: 0.1821 - val_accuracy: 0.9973\n",
      "Epoch 285/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.1524 - accuracy: 0.9993 - val_loss: 0.1932 - val_accuracy: 0.9980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1516 - accuracy: 0.9998 - val_loss: 0.1757 - val_accuracy: 0.9980\n",
      "Epoch 287/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1530 - accuracy: 0.9991 - val_loss: 0.1684 - val_accuracy: 0.9973\n",
      "Epoch 288/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1507 - accuracy: 0.9995 - val_loss: 0.1642 - val_accuracy: 0.9986\n",
      "Epoch 289/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1505 - accuracy: 0.9998 - val_loss: 0.1727 - val_accuracy: 0.9986\n",
      "Epoch 290/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1504 - accuracy: 0.9997 - val_loss: 0.1799 - val_accuracy: 0.9980\n",
      "Epoch 291/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1495 - accuracy: 1.0000 - val_loss: 0.1658 - val_accuracy: 0.9980\n",
      "Epoch 292/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.1502 - accuracy: 0.9997 - val_loss: 0.1824 - val_accuracy: 0.9966\n",
      "Epoch 293/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1519 - accuracy: 0.9988 - val_loss: 0.1671 - val_accuracy: 0.9980\n",
      "Epoch 294/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.1487 - accuracy: 0.9998 - val_loss: 0.1757 - val_accuracy: 0.9980\n",
      "Epoch 295/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1487 - accuracy: 0.9997 - val_loss: 0.1602 - val_accuracy: 0.9986\n",
      "Epoch 296/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.1481 - accuracy: 0.9998 - val_loss: 0.1624 - val_accuracy: 0.9986\n",
      "Epoch 297/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1479 - accuracy: 0.9998 - val_loss: 0.1608 - val_accuracy: 0.9986\n",
      "Epoch 298/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1488 - accuracy: 0.9997 - val_loss: 0.1703 - val_accuracy: 0.9980\n",
      "Epoch 299/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1492 - accuracy: 0.9991 - val_loss: 0.1707 - val_accuracy: 0.9973\n",
      "Epoch 300/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1479 - accuracy: 0.9997 - val_loss: 0.1620 - val_accuracy: 0.9986\n",
      "Epoch 301/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1461 - accuracy: 0.9998 - val_loss: 0.1642 - val_accuracy: 0.9973\n",
      "Epoch 302/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1463 - accuracy: 0.9995 - val_loss: 0.1514 - val_accuracy: 0.9993\n",
      "Epoch 303/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1453 - accuracy: 1.0000 - val_loss: 0.1636 - val_accuracy: 0.9980\n",
      "Epoch 304/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1452 - accuracy: 0.9998 - val_loss: 0.1565 - val_accuracy: 0.9986\n",
      "Epoch 305/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1450 - accuracy: 0.9998 - val_loss: 0.1723 - val_accuracy: 0.9966\n",
      "Epoch 306/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1449 - accuracy: 0.9998 - val_loss: 0.1730 - val_accuracy: 0.9980\n",
      "Epoch 307/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1440 - accuracy: 1.0000 - val_loss: 0.1600 - val_accuracy: 0.9980\n",
      "Epoch 308/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1436 - accuracy: 1.0000 - val_loss: 0.1488 - val_accuracy: 0.9986\n",
      "Epoch 309/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1432 - accuracy: 1.0000 - val_loss: 0.1501 - val_accuracy: 0.9986\n",
      "Epoch 310/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1436 - accuracy: 0.9997 - val_loss: 0.1871 - val_accuracy: 0.9980\n",
      "Epoch 311/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1433 - accuracy: 0.9997 - val_loss: 0.1569 - val_accuracy: 0.9966\n",
      "Epoch 312/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1424 - accuracy: 0.9998 - val_loss: 0.1630 - val_accuracy: 0.9980\n",
      "Epoch 313/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1430 - accuracy: 0.9997 - val_loss: 0.1511 - val_accuracy: 0.9980\n",
      "Epoch 314/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1417 - accuracy: 0.9998 - val_loss: 0.1696 - val_accuracy: 0.9959\n",
      "Epoch 315/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1445 - accuracy: 0.9990 - val_loss: 0.1978 - val_accuracy: 0.9952\n",
      "Epoch 316/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.1423 - accuracy: 0.9993 - val_loss: 0.1955 - val_accuracy: 0.9980\n",
      "Epoch 317/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1413 - accuracy: 0.9993 - val_loss: 0.1709 - val_accuracy: 0.9973\n",
      "Epoch 318/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1415 - accuracy: 0.9997 - val_loss: 0.1768 - val_accuracy: 0.9973\n",
      "Epoch 319/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1401 - accuracy: 1.0000 - val_loss: 0.1606 - val_accuracy: 0.9980\n",
      "Epoch 320/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1397 - accuracy: 1.0000 - val_loss: 0.1611 - val_accuracy: 0.9980\n",
      "Epoch 321/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1394 - accuracy: 1.0000 - val_loss: 0.1617 - val_accuracy: 0.9986\n",
      "Epoch 322/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1397 - accuracy: 0.9998 - val_loss: 0.1580 - val_accuracy: 0.9973\n",
      "Epoch 323/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1387 - accuracy: 1.0000 - val_loss: 0.1662 - val_accuracy: 0.9980\n",
      "Epoch 324/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1386 - accuracy: 1.0000 - val_loss: 0.1645 - val_accuracy: 0.9973\n",
      "Epoch 325/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1381 - accuracy: 1.0000 - val_loss: 0.1779 - val_accuracy: 0.9980\n",
      "Epoch 326/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1380 - accuracy: 0.9998 - val_loss: 0.1615 - val_accuracy: 0.9980\n",
      "Epoch 327/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1376 - accuracy: 1.0000 - val_loss: 0.1629 - val_accuracy: 0.9986\n",
      "Epoch 328/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1374 - accuracy: 1.0000 - val_loss: 0.1714 - val_accuracy: 0.9980\n",
      "Epoch 329/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1368 - accuracy: 0.9998 - val_loss: 0.1863 - val_accuracy: 0.9980\n",
      "Epoch 330/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1364 - accuracy: 1.0000 - val_loss: 0.2017 - val_accuracy: 0.9973\n",
      "Epoch 331/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1361 - accuracy: 0.9998 - val_loss: 0.1714 - val_accuracy: 0.9966\n",
      "Epoch 332/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1357 - accuracy: 1.0000 - val_loss: 0.1778 - val_accuracy: 0.9980\n",
      "Epoch 333/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1358 - accuracy: 0.9997 - val_loss: 0.1569 - val_accuracy: 0.9986\n",
      "Epoch 334/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1355 - accuracy: 0.9998 - val_loss: 0.1664 - val_accuracy: 0.9980\n",
      "Epoch 335/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1349 - accuracy: 0.9998 - val_loss: 0.1699 - val_accuracy: 0.9980\n",
      "Epoch 336/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.1346 - accuracy: 0.9998 - val_loss: 0.1745 - val_accuracy: 0.9966\n",
      "Epoch 337/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.1344 - accuracy: 0.9998 - val_loss: 0.1632 - val_accuracy: 0.9980\n",
      "Epoch 338/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.1337 - accuracy: 1.0000 - val_loss: 0.1508 - val_accuracy: 0.9980\n",
      "Epoch 339/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.1334 - accuracy: 1.0000 - val_loss: 0.1520 - val_accuracy: 0.9980\n",
      "Epoch 340/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.1335 - accuracy: 0.9998 - val_loss: 0.1611 - val_accuracy: 0.9980\n",
      "Epoch 341/500\n",
      "42/42 [==============================] - 138s 3s/step - loss: 0.1328 - accuracy: 0.9998 - val_loss: 0.1872 - val_accuracy: 0.9973\n",
      "Epoch 342/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1324 - accuracy: 0.9998 - val_loss: 0.1668 - val_accuracy: 0.9980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1323 - accuracy: 0.9997 - val_loss: 0.1695 - val_accuracy: 0.9980\n",
      "Epoch 344/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1352 - accuracy: 0.9995 - val_loss: 0.1824 - val_accuracy: 0.9966\n",
      "Epoch 345/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1330 - accuracy: 0.9995 - val_loss: 0.1917 - val_accuracy: 0.9980\n",
      "Epoch 346/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1318 - accuracy: 0.9995 - val_loss: 0.1335 - val_accuracy: 0.9993\n",
      "Epoch 347/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1307 - accuracy: 1.0000 - val_loss: 0.1450 - val_accuracy: 0.9986\n",
      "Epoch 348/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1305 - accuracy: 1.0000 - val_loss: 0.1559 - val_accuracy: 0.9966\n",
      "Epoch 349/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1301 - accuracy: 0.9997 - val_loss: 0.1540 - val_accuracy: 0.9980\n",
      "Epoch 350/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1297 - accuracy: 1.0000 - val_loss: 0.1524 - val_accuracy: 0.9986\n",
      "Epoch 351/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1295 - accuracy: 1.0000 - val_loss: 0.1437 - val_accuracy: 0.9980\n",
      "Epoch 352/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1298 - accuracy: 0.9997 - val_loss: 0.1504 - val_accuracy: 0.9980\n",
      "Epoch 353/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1293 - accuracy: 0.9998 - val_loss: 0.1465 - val_accuracy: 0.9980\n",
      "Epoch 354/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1301 - accuracy: 0.9993 - val_loss: 0.1362 - val_accuracy: 0.9986\n",
      "Epoch 355/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1289 - accuracy: 0.9995 - val_loss: 0.1456 - val_accuracy: 0.9980\n",
      "Epoch 356/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1278 - accuracy: 0.9997 - val_loss: 0.1475 - val_accuracy: 0.9986\n",
      "Epoch 357/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1316 - accuracy: 0.9990 - val_loss: 0.1324 - val_accuracy: 0.9993\n",
      "Epoch 358/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1294 - accuracy: 0.9997 - val_loss: 0.1753 - val_accuracy: 0.9980\n",
      "Epoch 359/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1277 - accuracy: 0.9997 - val_loss: 0.1603 - val_accuracy: 0.9980\n",
      "Epoch 360/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1270 - accuracy: 0.9997 - val_loss: 0.1504 - val_accuracy: 0.9980\n",
      "Epoch 361/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.1290 - accuracy: 0.9993 - val_loss: 0.1678 - val_accuracy: 0.9980\n",
      "Epoch 362/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1263 - accuracy: 0.9997 - val_loss: 0.1509 - val_accuracy: 0.9973\n",
      "Epoch 363/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1260 - accuracy: 0.9995 - val_loss: 0.1677 - val_accuracy: 0.9973\n",
      "Epoch 364/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.1256 - accuracy: 0.9997 - val_loss: 0.1627 - val_accuracy: 0.9980\n",
      "Epoch 365/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.1260 - accuracy: 0.9998 - val_loss: 0.1548 - val_accuracy: 0.9980\n",
      "Epoch 366/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1247 - accuracy: 1.0000 - val_loss: 0.1570 - val_accuracy: 0.9980\n",
      "Epoch 367/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1248 - accuracy: 0.9997 - val_loss: 0.1453 - val_accuracy: 0.9973\n",
      "Epoch 368/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1241 - accuracy: 1.0000 - val_loss: 0.1520 - val_accuracy: 0.9973\n",
      "Epoch 369/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1257 - accuracy: 0.9993 - val_loss: 0.1580 - val_accuracy: 0.9980\n",
      "Epoch 370/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1239 - accuracy: 0.9998 - val_loss: 0.1470 - val_accuracy: 0.9980\n",
      "Epoch 371/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1236 - accuracy: 0.9998 - val_loss: 0.1623 - val_accuracy: 0.9980\n",
      "Epoch 372/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1231 - accuracy: 0.9998 - val_loss: 0.1403 - val_accuracy: 0.9980\n",
      "Epoch 373/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1228 - accuracy: 1.0000 - val_loss: 0.1569 - val_accuracy: 0.9973\n",
      "Epoch 374/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1223 - accuracy: 1.0000 - val_loss: 0.1608 - val_accuracy: 0.9973\n",
      "Epoch 375/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1222 - accuracy: 1.0000 - val_loss: 0.1306 - val_accuracy: 0.9986\n",
      "Epoch 376/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1218 - accuracy: 0.9998 - val_loss: 0.1404 - val_accuracy: 0.9973\n",
      "Epoch 377/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1214 - accuracy: 1.0000 - val_loss: 0.1484 - val_accuracy: 0.9980\n",
      "Epoch 378/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1211 - accuracy: 1.0000 - val_loss: 0.1492 - val_accuracy: 0.9980\n",
      "Epoch 379/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1213 - accuracy: 0.9997 - val_loss: 0.1301 - val_accuracy: 0.9980\n",
      "Epoch 380/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1233 - accuracy: 0.9990 - val_loss: 0.1631 - val_accuracy: 0.9980\n",
      "Epoch 381/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1206 - accuracy: 0.9997 - val_loss: 0.1830 - val_accuracy: 0.9959\n",
      "Epoch 382/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1203 - accuracy: 0.9998 - val_loss: 0.1603 - val_accuracy: 0.9973\n",
      "Epoch 383/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1209 - accuracy: 0.9998 - val_loss: 0.1419 - val_accuracy: 0.9973\n",
      "Epoch 384/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1199 - accuracy: 0.9997 - val_loss: 0.1430 - val_accuracy: 0.9986\n",
      "Epoch 385/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1202 - accuracy: 0.9997 - val_loss: 0.1461 - val_accuracy: 0.9980\n",
      "Epoch 386/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1211 - accuracy: 0.9993 - val_loss: 0.1314 - val_accuracy: 0.9980\n",
      "Epoch 387/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1193 - accuracy: 0.9998 - val_loss: 0.1441 - val_accuracy: 0.9980\n",
      "Epoch 388/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1192 - accuracy: 0.9997 - val_loss: 0.1493 - val_accuracy: 0.9980\n",
      "Epoch 389/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1195 - accuracy: 0.9997 - val_loss: 0.1498 - val_accuracy: 0.9980\n",
      "Epoch 390/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1185 - accuracy: 0.9997 - val_loss: 0.1546 - val_accuracy: 0.9973\n",
      "Epoch 391/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1175 - accuracy: 0.9998 - val_loss: 0.1527 - val_accuracy: 0.9980\n",
      "Epoch 392/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1172 - accuracy: 1.0000 - val_loss: 0.1697 - val_accuracy: 0.9980\n",
      "Epoch 393/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1169 - accuracy: 1.0000 - val_loss: 0.1582 - val_accuracy: 0.9986\n",
      "Epoch 394/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.1167 - accuracy: 1.0000 - val_loss: 0.1368 - val_accuracy: 0.9973\n",
      "Epoch 395/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1164 - accuracy: 1.0000 - val_loss: 0.1366 - val_accuracy: 0.9986\n",
      "Epoch 396/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1161 - accuracy: 0.9998 - val_loss: 0.1557 - val_accuracy: 0.9966\n",
      "Epoch 397/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1165 - accuracy: 0.9997 - val_loss: 0.1446 - val_accuracy: 0.9980\n",
      "Epoch 398/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1162 - accuracy: 0.9997 - val_loss: 0.1432 - val_accuracy: 0.9986\n",
      "Epoch 399/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1165 - accuracy: 0.9993 - val_loss: 0.1775 - val_accuracy: 0.9973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1150 - accuracy: 0.9998 - val_loss: 0.1595 - val_accuracy: 0.9980\n",
      "Epoch 401/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1155 - accuracy: 0.9998 - val_loss: 0.1502 - val_accuracy: 0.9980\n",
      "Epoch 402/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1147 - accuracy: 0.9998 - val_loss: 0.1574 - val_accuracy: 0.9980\n",
      "Epoch 403/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1141 - accuracy: 1.0000 - val_loss: 0.1326 - val_accuracy: 0.9980\n",
      "Epoch 404/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1140 - accuracy: 0.9998 - val_loss: 0.1526 - val_accuracy: 0.9966\n",
      "Epoch 405/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1135 - accuracy: 1.0000 - val_loss: 0.1286 - val_accuracy: 0.9986\n",
      "Epoch 406/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1132 - accuracy: 1.0000 - val_loss: 0.1309 - val_accuracy: 0.9986\n",
      "Epoch 407/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1130 - accuracy: 1.0000 - val_loss: 0.1242 - val_accuracy: 0.9980\n",
      "Epoch 408/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1128 - accuracy: 0.9998 - val_loss: 0.1242 - val_accuracy: 0.9986\n",
      "Epoch 409/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1123 - accuracy: 1.0000 - val_loss: 0.1252 - val_accuracy: 0.9973\n",
      "Epoch 410/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1120 - accuracy: 1.0000 - val_loss: 0.1304 - val_accuracy: 0.9986\n",
      "Epoch 411/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1117 - accuracy: 1.0000 - val_loss: 0.1316 - val_accuracy: 0.9980\n",
      "Epoch 412/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1122 - accuracy: 0.9997 - val_loss: 0.1321 - val_accuracy: 0.9986\n",
      "Epoch 413/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1143 - accuracy: 0.9993 - val_loss: 0.1597 - val_accuracy: 0.9973\n",
      "Epoch 414/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1115 - accuracy: 0.9998 - val_loss: 0.1532 - val_accuracy: 0.9973\n",
      "Epoch 415/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1106 - accuracy: 1.0000 - val_loss: 0.1393 - val_accuracy: 0.9986\n",
      "Epoch 416/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1121 - accuracy: 0.9997 - val_loss: 0.1544 - val_accuracy: 0.9986\n",
      "Epoch 417/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1105 - accuracy: 0.9998 - val_loss: 0.1307 - val_accuracy: 0.9973\n",
      "Epoch 418/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1110 - accuracy: 0.9993 - val_loss: 0.1199 - val_accuracy: 0.9973\n",
      "Epoch 419/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1097 - accuracy: 0.9998 - val_loss: 0.1327 - val_accuracy: 0.9980\n",
      "Epoch 420/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1099 - accuracy: 1.0000 - val_loss: 0.1274 - val_accuracy: 0.9966\n",
      "Epoch 421/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1118 - accuracy: 0.9995 - val_loss: 0.1484 - val_accuracy: 0.9959\n",
      "Epoch 422/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1099 - accuracy: 0.9993 - val_loss: 0.1358 - val_accuracy: 0.9986\n",
      "Epoch 423/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1090 - accuracy: 0.9995 - val_loss: 0.1484 - val_accuracy: 0.9986\n",
      "Epoch 424/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1113 - accuracy: 0.9993 - val_loss: 0.1392 - val_accuracy: 0.9980\n",
      "Epoch 425/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1090 - accuracy: 0.9997 - val_loss: 0.1132 - val_accuracy: 0.9993\n",
      "Epoch 426/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1079 - accuracy: 1.0000 - val_loss: 0.1299 - val_accuracy: 0.9973\n",
      "Epoch 427/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1080 - accuracy: 0.9997 - val_loss: 0.1281 - val_accuracy: 0.9986\n",
      "Epoch 428/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1074 - accuracy: 0.9998 - val_loss: 0.1484 - val_accuracy: 0.9980\n",
      "Epoch 429/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1071 - accuracy: 1.0000 - val_loss: 0.1512 - val_accuracy: 0.9980\n",
      "Epoch 430/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1069 - accuracy: 0.9998 - val_loss: 0.1283 - val_accuracy: 0.9980\n",
      "Epoch 431/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1073 - accuracy: 0.9997 - val_loss: 0.1535 - val_accuracy: 0.9973\n",
      "Epoch 432/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1090 - accuracy: 0.9995 - val_loss: 0.1144 - val_accuracy: 0.9980\n",
      "Epoch 433/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1074 - accuracy: 0.9993 - val_loss: 0.1207 - val_accuracy: 0.9980\n",
      "Epoch 434/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1070 - accuracy: 0.9997 - val_loss: 0.1329 - val_accuracy: 0.9980\n",
      "Epoch 435/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1065 - accuracy: 0.9998 - val_loss: 0.1226 - val_accuracy: 0.9980\n",
      "Epoch 436/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1055 - accuracy: 1.0000 - val_loss: 0.1221 - val_accuracy: 0.9973\n",
      "Epoch 437/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1055 - accuracy: 0.9998 - val_loss: 0.1191 - val_accuracy: 0.9986\n",
      "Epoch 438/500\n",
      "42/42 [==============================] - 137s 3s/step - loss: 0.1051 - accuracy: 1.0000 - val_loss: 0.1346 - val_accuracy: 0.9986\n",
      "Epoch 439/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1048 - accuracy: 1.0000 - val_loss: 0.1219 - val_accuracy: 0.9973\n",
      "Epoch 440/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1047 - accuracy: 0.9998 - val_loss: 0.1142 - val_accuracy: 0.9986\n",
      "Epoch 441/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1044 - accuracy: 0.9998 - val_loss: 0.1133 - val_accuracy: 0.9986\n",
      "Epoch 442/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1040 - accuracy: 1.0000 - val_loss: 0.1257 - val_accuracy: 0.9966\n",
      "Epoch 443/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1038 - accuracy: 1.0000 - val_loss: 0.1259 - val_accuracy: 0.9980\n",
      "Epoch 444/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1038 - accuracy: 0.9998 - val_loss: 0.1313 - val_accuracy: 0.9986\n",
      "Epoch 445/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1036 - accuracy: 0.9998 - val_loss: 0.1374 - val_accuracy: 0.9980\n",
      "Epoch 446/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1031 - accuracy: 1.0000 - val_loss: 0.1343 - val_accuracy: 0.9980\n",
      "Epoch 447/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1028 - accuracy: 1.0000 - val_loss: 0.1260 - val_accuracy: 0.9980\n",
      "Epoch 448/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1032 - accuracy: 0.9998 - val_loss: 0.1359 - val_accuracy: 0.9980\n",
      "Epoch 449/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1023 - accuracy: 1.0000 - val_loss: 0.1321 - val_accuracy: 0.9980\n",
      "Epoch 450/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1032 - accuracy: 0.9997 - val_loss: 0.1256 - val_accuracy: 0.9980\n",
      "Epoch 451/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1018 - accuracy: 1.0000 - val_loss: 0.1483 - val_accuracy: 0.9980\n",
      "Epoch 452/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1021 - accuracy: 0.9997 - val_loss: 0.1366 - val_accuracy: 0.9973\n",
      "Epoch 453/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1018 - accuracy: 0.9998 - val_loss: 0.1238 - val_accuracy: 0.9980\n",
      "Epoch 454/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1023 - accuracy: 0.9995 - val_loss: 0.1185 - val_accuracy: 0.9986\n",
      "Epoch 455/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1022 - accuracy: 0.9995 - val_loss: 0.1288 - val_accuracy: 0.9980\n",
      "Epoch 456/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1022 - accuracy: 0.9993 - val_loss: 0.1050 - val_accuracy: 0.9993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1005 - accuracy: 0.9998 - val_loss: 0.1058 - val_accuracy: 0.9980\n",
      "Epoch 458/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1003 - accuracy: 0.9997 - val_loss: 0.1141 - val_accuracy: 0.9986\n",
      "Epoch 459/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1000 - accuracy: 0.9998 - val_loss: 0.1073 - val_accuracy: 0.9993\n",
      "Epoch 460/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.1005 - accuracy: 0.9998 - val_loss: 0.1073 - val_accuracy: 0.9986\n",
      "Epoch 461/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1036 - accuracy: 0.9991 - val_loss: 0.1222 - val_accuracy: 0.9973\n",
      "Epoch 462/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1005 - accuracy: 0.9995 - val_loss: 0.1260 - val_accuracy: 0.9973\n",
      "Epoch 463/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.0991 - accuracy: 1.0000 - val_loss: 0.1211 - val_accuracy: 0.9973\n",
      "Epoch 464/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1020 - accuracy: 0.9991 - val_loss: 0.1341 - val_accuracy: 0.9966\n",
      "Epoch 465/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.0999 - accuracy: 0.9993 - val_loss: 0.1274 - val_accuracy: 0.9980\n",
      "Epoch 466/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.0994 - accuracy: 0.9998 - val_loss: 0.1201 - val_accuracy: 0.9966\n",
      "Epoch 467/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.0986 - accuracy: 0.9998 - val_loss: 0.1045 - val_accuracy: 0.9986\n",
      "Epoch 468/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.0986 - accuracy: 0.9998 - val_loss: 0.1129 - val_accuracy: 0.9986\n",
      "Epoch 469/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.0991 - accuracy: 0.9997 - val_loss: 0.1173 - val_accuracy: 0.9986\n",
      "Epoch 470/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.0977 - accuracy: 0.9998 - val_loss: 0.1033 - val_accuracy: 0.9986\n",
      "Epoch 471/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.0979 - accuracy: 0.9997 - val_loss: 0.1162 - val_accuracy: 0.9986\n",
      "Epoch 472/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.0972 - accuracy: 1.0000 - val_loss: 0.1206 - val_accuracy: 0.9986\n",
      "Epoch 473/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.0970 - accuracy: 1.0000 - val_loss: 0.1107 - val_accuracy: 0.9986\n",
      "Epoch 474/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.0969 - accuracy: 1.0000 - val_loss: 0.1325 - val_accuracy: 0.9980\n",
      "Epoch 475/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1004 - accuracy: 0.9991 - val_loss: 0.1207 - val_accuracy: 0.9973\n",
      "Epoch 476/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.0966 - accuracy: 0.9998 - val_loss: 0.1251 - val_accuracy: 0.9973\n",
      "Epoch 477/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.0975 - accuracy: 0.9995 - val_loss: 0.1194 - val_accuracy: 0.9980\n",
      "Epoch 478/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.0961 - accuracy: 1.0000 - val_loss: 0.1175 - val_accuracy: 0.9980\n",
      "Epoch 479/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.0959 - accuracy: 0.9998 - val_loss: 0.1270 - val_accuracy: 0.9980\n",
      "Epoch 480/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.0966 - accuracy: 0.9998 - val_loss: 0.1321 - val_accuracy: 0.9980\n",
      "Epoch 481/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.0954 - accuracy: 0.9998 - val_loss: 0.1300 - val_accuracy: 0.9966\n",
      "Epoch 482/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.0952 - accuracy: 1.0000 - val_loss: 0.1533 - val_accuracy: 0.9966\n",
      "Epoch 483/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.0952 - accuracy: 1.0000 - val_loss: 0.1195 - val_accuracy: 0.9980\n",
      "Epoch 484/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.0948 - accuracy: 1.0000 - val_loss: 0.1378 - val_accuracy: 0.9980\n",
      "Epoch 485/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.0946 - accuracy: 1.0000 - val_loss: 0.1304 - val_accuracy: 0.9980\n",
      "Epoch 486/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.0946 - accuracy: 0.9998 - val_loss: 0.1302 - val_accuracy: 0.9980\n",
      "Epoch 487/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.0942 - accuracy: 1.0000 - val_loss: 0.1531 - val_accuracy: 0.9986\n",
      "Epoch 488/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.0940 - accuracy: 1.0000 - val_loss: 0.1231 - val_accuracy: 0.9980\n",
      "Epoch 489/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.0941 - accuracy: 0.9998 - val_loss: 0.1454 - val_accuracy: 0.9980\n",
      "Epoch 490/500\n",
      "42/42 [==============================] - 136s 3s/step - loss: 0.0936 - accuracy: 1.0000 - val_loss: 0.1169 - val_accuracy: 0.9980\n",
      "Epoch 491/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.0934 - accuracy: 1.0000 - val_loss: 0.1180 - val_accuracy: 0.9980\n",
      "Epoch 492/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.0933 - accuracy: 0.9998 - val_loss: 0.1244 - val_accuracy: 0.9980\n",
      "Epoch 493/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.0938 - accuracy: 0.9997 - val_loss: 0.1108 - val_accuracy: 0.9980\n",
      "Epoch 494/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.0930 - accuracy: 0.9995 - val_loss: 0.1362 - val_accuracy: 0.9980\n",
      "Epoch 495/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.0943 - accuracy: 0.9993 - val_loss: 0.1169 - val_accuracy: 0.9986\n",
      "Epoch 496/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.1020 - accuracy: 0.9983 - val_loss: 0.1320 - val_accuracy: 0.9973\n",
      "Epoch 497/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.0926 - accuracy: 0.9995 - val_loss: 0.1290 - val_accuracy: 0.9980\n",
      "Epoch 498/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.0919 - accuracy: 1.0000 - val_loss: 0.1365 - val_accuracy: 0.9973\n",
      "Epoch 499/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.0918 - accuracy: 1.0000 - val_loss: 0.1359 - val_accuracy: 0.9980\n",
      "Epoch 500/500\n",
      "42/42 [==============================] - 135s 3s/step - loss: 0.0929 - accuracy: 0.9997 - val_loss: 0.1388 - val_accuracy: 0.9980\n"
     ]
    }
   ],
   "source": [
    "history_bayes = model_bayes.fit(\n",
    "      train_generator,\n",
    "      validation_data=val_generator,\n",
    "      epochs=500,\n",
    "      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a7d053ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 31s 737ms/step - loss: 0.0914 - accuracy: 1.0000\n",
      "Accuracy of train datasets =  100.0 %\n",
      "40/40 [==============================] - 7s 182ms/step - loss: 0.1343 - accuracy: 0.9980\n",
      "Accuracy of valid datasets =  99.79522228240967 %\n"
     ]
    }
   ],
   "source": [
    "_,train_acc = model_bayes.evaluate(train_generator)\n",
    "print('Accuracy of train datasets = ', (train_acc * 100.0), \"%\")\n",
    "\n",
    "_,valid_acc = model_bayes.evaluate(val_generator)\n",
    "print('Accuracy of valid datasets = ', (valid_acc * 100.0), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1d64b2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 224\n",
    "dataset = []\n",
    "label = []\n",
    "\n",
    "pneumothorax_images = os.listdir('Dataset2/test/Stroke/')\n",
    "for i, image_name in enumerate(pneumothorax_images):\n",
    "    image = cv2.imread('Dataset2/test/Stroke/' + image_name)\n",
    "    image = Image.fromarray(image)\n",
    "    image = image.resize((size,size))\n",
    "    dataset.append(np.array(image))\n",
    "    label.append(1)\n",
    "        \n",
    "normal_images = os.listdir('Dataset2/test/Normal/')\n",
    "for i, image_name in enumerate(normal_images):\n",
    "    image = cv2.imread('Dataset2/test/Normal/' + image_name)\n",
    "    image = Image.fromarray(image)\n",
    "    image = image.resize((size,size))\n",
    "    dataset.append(np.array(image))\n",
    "    label.append(0)\n",
    "\n",
    "dataset = np.array(dataset)\n",
    "label = np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ea4e13cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = dataset\n",
    "y_test = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9da81cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test/255.\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7488aafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 7s 89ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = np.argmax(model_bayes.predict(X_test), axis=1)\n",
    "cm = confusion_matrix(np.argmax(y_test, axis=1), y_pred)\n",
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5966286f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pneumothorax_images_idx = np.where(y_pred == 1)[0]\n",
    "predicted_as_para = []\n",
    "for i in pneumothorax_images_idx:\n",
    "    pneu_img = X_test[i]\n",
    "    predicted_as_para.append(pneu_img)\n",
    "    \n",
    "predicted_as_para = np.array(predicted_as_para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "117939c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(img):\n",
    "    pred = model_bayes.predict(np.expand_dims(img, axis=0))\n",
    "    pred_class = np.argmax(pred)\n",
    "    last_layer_weights = model_bayes.layers[-1].get_weights()[0]\n",
    "    last_layer_weights_for_pred = last_layer_weights[:, pred_class]\n",
    "    last_conv_model = Model(model_bayes.input, model_bayes.get_layer(\"one_hot_categorical\").output)\n",
    "    last_conv_output = last_conv_model.predict(img[np.newaxis,:,:,:])\n",
    "    last_conv_output = np.squeeze(last_conv_output)\n",
    "    \n",
    "    h = int(img.shape[0]/last_conv_output.shape[0])\n",
    "    w = int(img.shape[1]/last_conv_output.shape[1])\n",
    "    upsampled_last_conv_output = scipy.ndimage.zoom(last_conv_output, (h, w, 1), order=1)\n",
    "    \n",
    "    heat_map = np.dot(upsampled_last_conv_output.reshape((img.shape[0]*img.shape[1], 64)), \n",
    "                 last_layer_weights_for_pred).reshape(img.shape[0],img.shape[1])\n",
    "    \n",
    "    heat_map[img[:,:,0] == 0] = 0 \n",
    "     \n",
    "    peak_coords = peak_local_max(heat_map, num_peaks=5, threshold_rel=0.5, min_distance=10) \n",
    "\n",
    "    plt.imshow(img.astype('float32').reshape(img.shape[0],img.shape[1],3))\n",
    "    plt.imshow(heat_map, cmap='jet', alpha=0.30)\n",
    "    for i in range(0,peak_coords.shape[0]):\n",
    "        print(i)\n",
    "        y = peak_coords[i,0]\n",
    "        x = peak_coords[i,1]\n",
    "        plt.gca().add_patch(Rectangle((x-25, y-25), 50,50,linewidth=1,edgecolor='r',facecolor='none'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f694ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m image \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m,predicted_as_para\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m heat_map \u001b[38;5;241m=\u001b[39m\u001b[43mplot_heatmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredicted_as_para\u001b[49m\u001b[43m[\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m img \u001b[38;5;241m=\u001b[39m predicted_as_para[image]\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(predicted_as_para[img])\n",
      "Cell \u001b[1;32mIn[32], line 4\u001b[0m, in \u001b[0;36mplot_heatmap\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m      2\u001b[0m pred \u001b[38;5;241m=\u001b[39m model_bayes\u001b[38;5;241m.\u001b[39mpredict(np\u001b[38;5;241m.\u001b[39mexpand_dims(img, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m      3\u001b[0m pred_class \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(pred)\n\u001b[1;32m----> 4\u001b[0m last_layer_weights \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_bayes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      5\u001b[0m last_layer_weights_for_pred \u001b[38;5;241m=\u001b[39m last_layer_weights[:, pred_class]\n\u001b[0;32m      6\u001b[0m last_conv_model \u001b[38;5;241m=\u001b[39m Model(model_bayes\u001b[38;5;241m.\u001b[39minput, model_bayes\u001b[38;5;241m.\u001b[39mget_layer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mone_hot_categorical\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39moutput)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "image = random.randint(0,predicted_as_para.shape[0]-1)\n",
    "heat_map = plot_heatmap(predicted_as_para[image])\n",
    "\n",
    "img = predicted_as_para[image]\n",
    "plt.imshow(predicted_as_para[img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2ea7876e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\keras\\saving\\serialization_lib.py:139: UserWarning: The object being serialized includes a `lambda`. This is unsafe. In order to reload the object, you will have to pass `safe_mode=False` to the loading function. Please avoid using `lambda` in the future, and use named Python functions instead. This is the `lambda` being serialized:         lambda t: OneHotCategorical.new(  # pylint: disable=g-long-lambda\n",
      "            t, event_size, sample_dtype, validate_args),\n",
      "\n",
      "  return [serialize_keras_object(x) for x in obj]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['bayesian_model.joblib']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(history_bayes, 'bayesian_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35ea095",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
